# TinyBERT-Pre-training
This repository is having all the codes used to Pretrain TinyBert of 4M Parameters on 12M tokens
